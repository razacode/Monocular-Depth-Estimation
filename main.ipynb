{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLU_Assignment_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUzVt3VFXoF0"
      },
      "source": [
        "##Assigment is in the intersection of Named Entity Recognition and Dependency Parsing.\n",
        "\n",
        "\n",
        "*   Evaluate spaCy NER on CoNLL 2003 data (provided)\n",
        "*   Report token-level performance (per class and total) accuracy of correctly recognizing all tokens that belong to named entities (i.e. tag-level accuracy) \n",
        "*   Report CoNLL chunk-level performance (per class and total); precision, recall, f-measure of correctly recognizing all the named entities in a chunk per class and total\n",
        "*   Write a function to group recognized named entities using noun_chunks method of spaCy. Analyze the groups in terms of most frequent combinations (i.e. NER types that go together). \n",
        "\n",
        "*   One of the possible post-processing steps is to fix segmentation errors. Write a function that extends the entity span to cover the full noun-compounds. Make use of compound dependency relation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5cwDDwM0d7x",
        "outputId": "48e53c1f-8cb3-473b-fecd-5fede20ad07d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmNJNA2FmnSU"
      },
      "source": [
        "#Unzip the conll2003 file\n",
        "!unzip \"file_path_to_unzip\" command is used to extract conll2003 file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eGgHejJlIQG"
      },
      "source": [
        "!unzip \"/content/conll2003.zip\" # file was unzipped with this line of code"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BiIknl3tm-CM"
      },
      "source": [
        "#Report token-level performance (per class and total) accuracy of correctly recognizing all tokens that belong to named entities (i.e. tag-level accuracy)\n",
        "\n",
        "#Report CoNLL chunk-level performance (per class and total); precision, recall, f-measure of correctly recognizing all the named entities in a chunk per class and total\n",
        "To start we import the libraries, spacy and from spacy.token we import Doc. From spacy documentation A Doc is a sequence of Token objects. Access sentences and named entities, export annotations to numpy arrays, losslessly serialize to compressed binary strings. The Doc object holds an array of TokenC structs. The Python-level Token and Span objects are views of this array, i.e. they donâ€™t own the data themselves.\n",
        "\n",
        "conll2003 dataset was used for evaluation. Along with this conll.py file was provided which is used for evaluation.\n",
        "The first function **name_Entity_Recognition_Spacy_Accuracy** consist of a the details for computing accuracy and parse_iob function is used from conll to check the list. The obtained data is saved in dicts dictonary for each class and then it will print total accuracy of the class.\n",
        "For the function **name_Entity_Recognition_Spacy** is created for evaluate function from conll in order to calculate and print the  precision, recall, f1-score and support.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JaL9clcm_Dy6",
        "outputId": "f6b4fba1-c313-467f-8b59-ab1457a0d2c1"
      },
      "source": [
        "import spacy\n",
        "from spacy.tokens import Doc\n",
        "import conll\n",
        "import pandas as pd\n",
        "\n",
        "def name_Entity_Recognition_Spacy_Accuracy(hyps,refs):\n",
        "\n",
        "    accList = []\n",
        "    for i in range(len(refs)):\n",
        "        for j in range(len(refs[i])):\n",
        "            accList.append((refs[i][j][1], hyps[i][j][1]))\n",
        "\n",
        "    total = sum(a == b for a, b in accList)\n",
        "    accu = total / len(accList)\n",
        "\n",
        "    dicts = {}\n",
        "\n",
        "    for a in accList:\n",
        "        conll_hyp, conll_ref = conll.parse_iob(a[0]), conll.parse_iob(a[1])\n",
        "\n",
        "        empty = None\n",
        "        if conll_ref[1]  !=empty:\n",
        "            if conll_hyp[1] !=empty:\n",
        "                if conll_ref[1] in dicts:\n",
        "                    dicts[conll_ref[1]][0] = dicts[conll_ref[1]][0] + 1\n",
        "                else:\n",
        "                    dicts[conll_ref[1]] = [1, 0]\n",
        "                if conll_ref == conll_hyp:\n",
        "                    dicts[conll_ref[1]][1] = dicts[conll_ref[1]][1] + 1\n",
        "\n",
        "    for key, value in dicts.items():\n",
        "        print(\"{}:\\t----->  {:.4f}\".format(key, value[1] / value[0]))\n",
        "    print(\"Total:\\t----->  {:.4f}\".format(accu))\n",
        "\n",
        "name_Entity_Recognition_Spacy_Accuracy(hyps,refs)\n"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ORG:\t----->  0.7579\n",
            "MISC:\t----->  0.8525\n",
            "PER:\t----->  0.8571\n",
            "LOC:\t----->  0.9174\n",
            "Total:\t----->  0.8737\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SsSPwV3RBbii",
        "outputId": "1ec44b76-3698-4753-d1ba-c254d1dad0b0"
      },
      "source": [
        "def name_Entity_Recognition_Spacy(refs, hyps):\n",
        " \n",
        "  outcome = conll.evaluate(refs, hyps)\n",
        "\n",
        "  pd_tbl = pandas.DataFrame().from_dict(outcome, orient='index')\n",
        "  print(pd_tbl.round(decimals=3))\n",
        "  \n",
        "name_Entity_Recognition_Spacy(refs, hyps)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "           p      r      f    s\n",
            "MISC   0.275  0.721  0.398   61\n",
            "PER    0.821  0.681  0.744   47\n",
            "ORG    0.453  0.500  0.475   58\n",
            "LOC    0.942  0.843  0.890  115\n",
            "total  0.552  0.719  0.624  281\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4EXicInvF_T",
        "outputId": "ea34e8b7-27d2-463d-d0bd-943600e1d429"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "conll_ref = [tok[-1] for sent in refs for tok in sent]\n",
        "conll_hyp = [tok[-1] for sent in hyps for tok in sent]\n",
        "\n",
        "result = classification_report(conll_ref, conll_hyp)\n",
        "    \n",
        "print(result)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-LOC       0.94      0.84      0.89       115\n",
            "      B-MISC       0.31      0.82      0.45        61\n",
            "       B-ORG       0.50      0.55      0.52        58\n",
            "       B-PER       0.82      0.68      0.74        47\n",
            "       I-LOC       0.38      0.60      0.46         5\n",
            "      I-MISC       0.03      0.18      0.05        11\n",
            "       I-ORG       0.60      0.75      0.67        53\n",
            "       I-PER       0.72      0.90      0.80        31\n",
            "           O       0.98      0.90      0.93      2026\n",
            "\n",
            "    accuracy                           0.87      2407\n",
            "   macro avg       0.59      0.69      0.61      2407\n",
            "weighted avg       0.93      0.87      0.89      2407\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RW67P7yhg2Z4"
      },
      "source": [
        "#Write a function to group recognized named entities using noun_chunks method of spaCy. Analyze the groups in terms of most frequent combinations (i.e. NER types that go together)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGgChda3xqYx"
      },
      "source": [
        "##One of the possible post-processing steps is to fix segmentation errors . Write a function that extends the entity span to cover the full noun-compounds. Make use of compound dependency relation.\n",
        "\n",
        "The function ***fix_Segmentation_Errors*** take text as single parameter which is intalize as **t**. Then list is created to store ents of the doc and t deal with the token that are out of for loop which is kind of a repeat words in simple way to avoide redundancy **igr** list is created.\n",
        "In for loop it look for correct leaeling with if else condition. Then if compound is not find in the enity same as of its head then it  will check if the tocken in ent not head in ent. If in the net element in doc is equal to the head it will append in the list and so on. The function **extends** print all the text along with their label of a given sentence.\n",
        "The reult is shown below the code.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3v0q_vvKfNfY",
        "outputId": "6166c2b0-3b34-4058-97b5-a90577927e88"
      },
      "source": [
        "#Example to evaluate the output\n",
        "import spacy\n",
        "\n",
        "nlp = spacy.load('en')\n",
        "\n",
        "txt = 'AL-AIN , United Arab Emirates 1996-12-06'\n",
        "\n",
        "doc = nlp(txt)\n",
        "\n",
        "print([(t.text, t.ent_type_) for t in doc])"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('AL', 'ORG'), ('-', 'ORG'), ('AIN', 'ORG'), (',', ''), ('United', 'GPE'), ('Arab', 'GPE'), ('Emirates', 'GPE'), ('1996', 'DATE'), ('-', 'DATE'), ('12', 'DATE'), ('-', 'DATE'), ('06', 'DATE')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Sy4wTO1xIfB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1ca6f95-469d-47c8-c604-f229ec49c00a"
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en\")\n",
        "def fix_Segmentation_Errors(t):\n",
        "    doc = nlp(t)\n",
        "    ent_res_list = []\n",
        "    igr = []\n",
        "    for i, token in enumerate(doc):\n",
        "      if (token.ent_iob_ == '') or  (token.ent_type_ == ''):\n",
        "        lab = token.ent_type_ \n",
        "        lab = token.ent_iob_\n",
        "      else:\n",
        "        lab = token.ent_iob_ + '-' + token.ent_type_\n",
        "        if (token.dep_ == 'compound'):\n",
        "          for k, ent in enumerate(doc.ents):\n",
        "            if ((token in ent) and (not(token.head in ent))):\n",
        "              if (token.head == doc[i+1]): \n",
        "                ent_res_list.append(spacy.tokens.Span(doc,i, i+1,lab)) and igr.append(token.head) \n",
        "              elif (token.head == doc[i-1]):\n",
        "                igr.append(token.head) and ent_res_list.append(spacy.tokens.Span(doc,i-1, i,lab))\n",
        "              break\n",
        "            elif (token in ent):\n",
        "              igr.append(token.head) and ent_res_list.append(spacy.tokens.Span(doc,ent.start, ent.end,lab))\n",
        "            break\n",
        "        elif (token not in igr):\n",
        "            ent_res_list.append(spacy.tokens.Span(doc,i, i+1,lab))\n",
        "    return doc\n",
        "\n",
        "def extends(t):\n",
        "    ent_res = fix_Segmentation_Errors(t)\n",
        "    stored = []\n",
        "    for ent in ent_res.ents:\n",
        "        stored.append((ent.text, ent.label_))\n",
        "    print(stored)\n",
        "\n",
        "sent = \"AL-AIN , United Arab Emirates 1996-12-06\"\n",
        "\n",
        "extends(sent)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('AL-AIN', 'ORG'), ('United Arab Emirates', 'GPE'), ('1996-12-06', 'DATE')]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}