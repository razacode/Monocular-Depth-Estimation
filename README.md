# Monocular Depth Estimation

## What is Knowledge Distillation 

Itâ€™s the procedure or the process for reducing the model complexity and computation overhead while maintaining the performance same as originally. One of the feasible way is to quantize the model, prune the redundant parameters and many more.

## Dependencies

Python

```
$ sudo apt-get install python3 python3-pip
```

Tensorflow

```
$ pip install tensorflow
# $ conda install -c conda-forge tensorflow
```

Opencv

```
$ pip install opencv-python
# $ conda install opencv-python
```

keras

```
$ pip install keras
# $ conda install -c conda-forge keras

```

NumPy

```
$ pip install numpy
# $ conda install numpy
```

Pandas

```
$ pip install pandas
# $ conda install pandas
```

Matplotlib

```
$ pip install matplotlib
# $ conda install matplotlib
```
## Result
![Result](https://github.com/razacode/Monocular-Depth-Estimation/blob/main/img/mde1.PNG)
### Here the first image is the RGB image, the second image is the ground truth depth map image and the third one is the predicted depth map image
![Result](https://github.com/razacode/Monocular-Depth-Estimation/blob/main/img/mde2.PNG)
